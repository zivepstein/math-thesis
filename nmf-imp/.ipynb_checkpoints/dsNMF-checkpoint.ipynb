{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosine\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "import itertools\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "from dsnmf import DSNMF, appr_seminmf\n",
    "n_topics = 20\n",
    "n_top_words = 20\n",
    "###fake data\n",
    "# dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "#                              remove=('headers', 'footers', 'quotes'))\n",
    "# data_samples = dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0198d68872b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msemi_supervised_nnmf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSSMF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ziv/GDrive/school/math-thesis/nmf-imp/semi_supervised_nnmf.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#(A,S,B) = ssnmf(X,L,Y,lamb,r,k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "dsnmf = DSNMF(X.toarray(), layers=(400, 100))\n",
    "for epoch in range(100):\n",
    "    residual = float(dsnmf.train_fun())\n",
    "    \n",
    "    print(\"Epoch {}. Residual [{:.2f}]\".format(epoch, residual))\n",
    "fea = dsnmf.get_features().T # this is the last layers features i.e. h_2\n",
    "pred = kmeans.fit_predict(fea)\n",
    "score = sklearn.metrics.normalized_mutual_info_score(gnd, pred)\n",
    "\n",
    "print(\"NMI: {:.2f}%\".format(100 * score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local_data = []\n",
    "classes = ['afghannationalliberationfront', 'hezbislami', 'jamiatislami']\n",
    "philes =  glob.glob(\"/Users/ziv/GDrive/school/math-thesis/nmf-imp/txt_data_bypage/*.txt\")\n",
    "Y = np.zeros((len(classes),len(philes)))\n",
    "for (i,phile) in enumerate(philes):\n",
    "    c = phile.split('/')[-1].split('_')[0]\n",
    "    cls = classes.index(c)\n",
    "    Y[cls,i]= 1\n",
    "    with open(phile, 'r') as myfile:\n",
    "        data=myfile.read().replace('\\n', '')\n",
    "        local_data.append(unicode(data, errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1830"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, #max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(local_data)\n",
    "k = len(classes)\n",
    "r = 10\n",
    "lamb = 1\n",
    "L = np.ones((k,X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tfdif and nmf model building\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, #max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(local_data)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "nmf = NMF(n_components=n_topics).fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "H = nmf.components_\n",
    "W = nmf.fit_transform(tfidf)\n",
    "#x = WH\n",
    "weights = (5000/W.sum())*W.sum(axis=0)\n",
    "\n",
    "def build_wgraph(alpha=2):\n",
    "    if alpha != 2:\n",
    "        return [[int(cosine(H[i],H[j])[0][0] > alpha) for i in range(0, len(H))] for j in range(0, len(H))]\n",
    "    else:\n",
    "        return [[cosine(H[i],H[j])[0][0] for i in range(0, len(H))] for j in range(0, len(H))]\n",
    "def thresh_vals(numbin):\n",
    "    binz = []\n",
    "    w = build_wgraph(2)\n",
    "    chain = itertools.chain(*w)\n",
    "    s =sorted(list(chain))\n",
    "    val = n_topics*n_topics/numbin\n",
    "    for i,v in enumerate(s):\n",
    "        if i%val ==0: binz.append(v)\n",
    "    return binz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def array_distance(A,B):\n",
    "    count = 0\n",
    "    for i,x in enumerate(A):\n",
    "        if x == B[i]:\n",
    "            count+=1\n",
    "    return len(A)-count\n",
    "\n",
    "def greedy_TV_build(to_consume,bins):\n",
    "    if len(to_consume)>1:\n",
    "        a = to_consume[0]\n",
    "        b = to_consume[1]\n",
    "        ccA = connected_components(build_wgraph(a))[1]\n",
    "        ccB = connected_components(build_wgraph(b))[1]\n",
    "        if not np.array_equal(ccA, ccB):\n",
    "            distance = array_distance(ccA,ccB)\n",
    "            if distance > 8:\n",
    "                new_tv = [a + i*(b-a)/bins for i in range(0,bins)]\n",
    "                return new_tv + greedy_TV_build( to_consume[1:], bins)\n",
    "            else:\n",
    "                return [a] + greedy_TV_build(to_consume[1:], bins)\n",
    "        else:\n",
    "            return greedy_TV_build(to_consume[1:], bins)\n",
    "    elif len(to_consume) == 1:\n",
    "        return to_consume\n",
    "    else:\n",
    "        return []\n",
    "  \n",
    "\n",
    "def populateTree(row_level, valid_community):\n",
    "    if row_level > size-2 :\n",
    "        return []\n",
    "    else:\n",
    "        children = []\n",
    "        parent_community = connected_components(build_wgraph(tv[row_level]))[1]\n",
    "        child_community = connected_components(build_wgraph(tv[row_level+1]))[1]\n",
    "        unique_communities = list(set(parent_community)) \n",
    "        for unique_community in unique_communities:\n",
    "            if valid_community == unique_community:\n",
    "                indices = [i for i, x in enumerate(parent_community) if x == unique_community] #[8,9]\n",
    "                seen_communities = []\n",
    "                for i in indices: #8 and 9\n",
    "                    if child_community[i] in seen_communities:\n",
    "                        filter(lambda x: x['community'] == str(child_community[i]), children)[0]['indices'].append(i)\n",
    "                    else:\n",
    "                        community_to_find = child_community[i]\n",
    "                        grow_my_children = populateTree(row_level+1, community_to_find)\n",
    "                        if grow_my_children:\n",
    "                            name = \"\"\n",
    "                            children.append({\"community\":str(child_community[i]),\"indices\":[i],\"name\" : name , \"children\":grow_my_children, \"hasChildren\": True})\n",
    "                        else:\n",
    "                            name = \" \".join([tfidf_feature_names[j] for j in nmf.components_[i].argsort()[:-n_top_words - 1:-1]])\n",
    "                            children.append({\"community\":str(child_community[i]),\"indices\":[i],\"size\":weights[i],\"name\":name, \"hasChildren\": False})\n",
    "                        seen_communities.append(child_community[i])\n",
    "        if len(children) == 1:\n",
    "            try: \n",
    "                return children[0]['children']\n",
    "            except:\n",
    "                return []\n",
    "        else:\n",
    "            return children\n",
    "        \n",
    "def recursiveNaming(tree):\n",
    "        i = tree['indices']\n",
    "        base = nmf.components_[i[0]]\n",
    "        if len(i) > 1:\n",
    "            for ind in i[1:]:\n",
    "                base = np.add(nmf.components_[ind], base)\n",
    "        tree['name'] = \" \".join([tfidf_feature_names[j] for j in base.argsort()[:-n_top_words - 1:-1]])\n",
    "        if tree['hasChildren']:\n",
    "            for child in tree['children']:\n",
    "                    recursiveNaming(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tv = greedy_TV_build(thresh_vals(100),2)\n",
    "# visualize topic tree\n",
    "# for i in tv:\n",
    "#     ccB = connected_components(build_wgraph(i))[1]\n",
    "#     print ccB\n",
    "size = len(tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flare = {\"name\" : \"\" , \"children\" : populateTree(0, 0)}\n",
    "for child in flare['children']:\n",
    "    recursiveNaming(child)\n",
    "with open('demo.json', 'w') as outfile:\n",
    "    json.dump(flare, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.063645809712599435,\n",
       " 0.07042121552949536,\n",
       " 0.071913670128555859,\n",
       " 0.076448673468941172,\n",
       " 0.12154825405128192,\n",
       " 0.15240319895942628,\n",
       " 0.17893480722565985,\n",
       " 0.41158435892964457,\n",
       " 0.43746089630853452,\n",
       " 1.0000000000000011]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
