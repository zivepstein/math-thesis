{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosine\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "import itertools\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "from dsnmf import DSNMF, appr_seminmf\n",
    "n_topics = 20\n",
    "n_top_words = 20\n",
    "###fake data\n",
    "# dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "#                              remove=('headers', 'footers', 'quotes'))\n",
    "# data_samples = dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local_data = []\n",
    "classes = ['afghannationalliberationfront', 'hezbislami', 'jamiatislami']\n",
    "philes =  glob.glob(\"/Users/ziv/GDrive/school/math-thesis/nmf-imp/txt_data_bypage/*.txt\")\n",
    "Y = np.zeros((len(classes),len(philes)))\n",
    "for (i,phile) in enumerate(philes):\n",
    "    c = phile.split('/')[-1].split('_')[0]\n",
    "    cls = classes.index(c)\n",
    "    Y[cls,i]= 1\n",
    "    with open(phile, 'r') as myfile:\n",
    "        data=myfile.read().replace('\\n', '')\n",
    "        local_data.append(unicode(data, errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, #max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(local_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Residual [1200.77]\n",
      "Epoch 1. Residual [25014.77]\n",
      "Epoch 2. Residual [2470.47]\n",
      "Epoch 3. Residual [4023.46]\n",
      "Epoch 4. Residual [9219.01]\n",
      "Epoch 5. Residual [8736.02]\n",
      "Epoch 6. Residual [5565.22]\n",
      "Epoch 7. Residual [3022.03]\n",
      "Epoch 8. Residual [1788.71]\n",
      "Epoch 9. Residual [1367.19]\n",
      "Epoch 10. Residual [1278.87]\n",
      "Epoch 11. Residual [1290.11]\n",
      "Epoch 12. Residual [1320.17]\n",
      "Epoch 13. Residual [1352.78]\n",
      "Epoch 14. Residual [1378.21]\n",
      "Epoch 15. Residual [1393.29]\n",
      "Epoch 16. Residual [1398.91]\n",
      "Epoch 17. Residual [1397.35]\n",
      "Epoch 18. Residual [1391.58]\n",
      "Epoch 19. Residual [1384.49]\n",
      "Epoch 20. Residual [1378.97]\n",
      "Epoch 21. Residual [1376.89]\n",
      "Epoch 22. Residual [1377.97]\n",
      "Epoch 23. Residual [1379.85]\n",
      "Epoch 24. Residual [1380.06]\n",
      "Epoch 25. Residual [1377.54]\n",
      "Epoch 26. Residual [1372.99]\n",
      "Epoch 27. Residual [1368.07]\n",
      "Epoch 28. Residual [1364.32]\n",
      "Epoch 29. Residual [1362.50]\n",
      "Epoch 30. Residual [1362.39]\n",
      "Epoch 31. Residual [1363.01]\n",
      "Epoch 32. Residual [1363.32]\n",
      "Epoch 33. Residual [1362.68]\n",
      "Epoch 34. Residual [1361.07]\n",
      "Epoch 35. Residual [1358.96]\n",
      "Epoch 36. Residual [1356.98]\n",
      "Epoch 37. Residual [1355.61]\n",
      "Epoch 38. Residual [1354.98]\n",
      "Epoch 39. Residual [1354.76]\n",
      "Epoch 40. Residual [1354.49]\n",
      "Epoch 41. Residual [1353.77]\n",
      "Epoch 42. Residual [1352.59]\n",
      "Epoch 43. Residual [1351.21]\n",
      "Epoch 44. Residual [1350.03]\n",
      "Epoch 45. Residual [1349.31]\n",
      "Epoch 46. Residual [1349.06]\n",
      "Epoch 47. Residual [1349.03]\n",
      "Epoch 48. Residual [1348.87]\n",
      "Epoch 49. Residual [1348.39]\n",
      "Epoch 50. Residual [1347.60]\n",
      "Epoch 51. Residual [1346.70]\n",
      "Epoch 52. Residual [1345.94]\n",
      "Epoch 53. Residual [1345.44]\n",
      "Epoch 54. Residual [1345.15]\n",
      "Epoch 55. Residual [1344.94]\n",
      "Epoch 56. Residual [1344.66]\n",
      "Epoch 57. Residual [1344.26]\n",
      "Epoch 58. Residual [1343.79]\n",
      "Epoch 59. Residual [1343.34]\n",
      "Epoch 60. Residual [1342.99]\n",
      "Epoch 61. Residual [1342.73]\n",
      "Epoch 62. Residual [1342.52]\n",
      "Epoch 63. Residual [1342.29]\n",
      "Epoch 64. Residual [1342.00]\n",
      "Epoch 65. Residual [1341.67]\n",
      "Epoch 66. Residual [1341.36]\n",
      "Epoch 67. Residual [1341.10]\n",
      "Epoch 68. Residual [1340.90]\n",
      "Epoch 69. Residual [1340.73]\n",
      "Epoch 70. Residual [1340.54]\n",
      "Epoch 71. Residual [1340.32]\n",
      "Epoch 72. Residual [1340.07]\n",
      "Epoch 73. Residual [1339.82]\n",
      "Epoch 74. Residual [1339.61]\n",
      "Epoch 75. Residual [1339.43]\n",
      "Epoch 76. Residual [1339.27]\n",
      "Epoch 77. Residual [1339.10]\n",
      "Epoch 78. Residual [1338.92]\n",
      "Epoch 79. Residual [1338.74]\n",
      "Epoch 80. Residual [1338.56]\n",
      "Epoch 81. Residual [1338.40]\n",
      "Epoch 82. Residual [1338.25]\n",
      "Epoch 83. Residual [1338.11]\n",
      "Epoch 84. Residual [1337.96]\n",
      "Epoch 85. Residual [1337.80]\n",
      "Epoch 86. Residual [1337.64]\n",
      "Epoch 87. Residual [1337.50]\n",
      "Epoch 88. Residual [1337.36]\n",
      "Epoch 89. Residual [1337.23]\n",
      "Epoch 90. Residual [1337.10]\n",
      "Epoch 91. Residual [1336.97]\n",
      "Epoch 92. Residual [1336.83]\n",
      "Epoch 93. Residual [1336.70]\n",
      "Epoch 94. Residual [1336.57]\n",
      "Epoch 95. Residual [1336.45]\n",
      "Epoch 96. Residual [1336.32]\n",
      "Epoch 97. Residual [1336.20]\n",
      "Epoch 98. Residual [1336.07]\n",
      "Epoch 99. Residual [1335.95]\n"
     ]
    }
   ],
   "source": [
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "dsnmf = DSNMF(X.toarray(), layers=(400, 100))\n",
    "for epoch in range(100):\n",
    "    residual = float(dsnmf.train_fun())\n",
    "    \n",
    "    print(\"Epoch {}. Residual [{:.2f}]\".format(epoch, residual))\n",
    "fea = dsnmf.get_features().T # this is the last layers features i.e. h_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a1 = dsnmf.get_param_values()[0]\n",
    "a2 = dsnmf.get_param_values()[1]\n",
    "s = dsnmf.get_param_values()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1511, 15380)\n",
      "(15380, 400)\n",
      "(400, 100)\n",
      "(100, 1511)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print a1.shape\n",
    "print a2.shape\n",
    "print s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nmf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-842ed33080d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#x = WH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nmf' is not defined"
     ]
    }
   ],
   "source": [
    "H = nmf.components_\n",
    "W = nmf.fit_transform(tfidf)\n",
    "#x = WH\n",
    "weights = (5000/W.sum())*W.sum(axis=0)\n",
    "\n",
    "def build_wgraph(alpha=2):\n",
    "    if alpha != 2:\n",
    "        return [[int(cosine(H[i],H[j])[0][0] > alpha) for i in range(0, len(H))] for j in range(0, len(H))]\n",
    "    else:\n",
    "        return [[cosine(H[i],H[j])[0][0] for i in range(0, len(H))] for j in range(0, len(H))]\n",
    "def thresh_vals(numbin):\n",
    "    binz = []\n",
    "    w = build_wgraph(2)\n",
    "    chain = itertools.chain(*w)\n",
    "    s =sorted(list(chain))\n",
    "    val = n_topics*n_topics/numbin\n",
    "    for i,v in enumerate(s):\n",
    "        if i%val ==0: binz.append(v)\n",
    "    return binz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def array_distance(A,B):\n",
    "    count = 0\n",
    "    for i,x in enumerate(A):\n",
    "        if x == B[i]:\n",
    "            count+=1\n",
    "    return len(A)-count\n",
    "\n",
    "def greedy_TV_build(to_consume,bins):\n",
    "    if len(to_consume)>1:\n",
    "        a = to_consume[0]\n",
    "        b = to_consume[1]\n",
    "        ccA = connected_components(build_wgraph(a))[1]\n",
    "        ccB = connected_components(build_wgraph(b))[1]\n",
    "        if not np.array_equal(ccA, ccB):\n",
    "            distance = array_distance(ccA,ccB)\n",
    "            if distance > 8:\n",
    "                new_tv = [a + i*(b-a)/bins for i in range(0,bins)]\n",
    "                return new_tv + greedy_TV_build( to_consume[1:], bins)\n",
    "            else:\n",
    "                return [a] + greedy_TV_build(to_consume[1:], bins)\n",
    "        else:\n",
    "            return greedy_TV_build(to_consume[1:], bins)\n",
    "    elif len(to_consume) == 1:\n",
    "        return to_consume\n",
    "    else:\n",
    "        return []\n",
    "  \n",
    "\n",
    "def populateTree(row_level, valid_community):\n",
    "    if row_level > size-2 :\n",
    "        return []\n",
    "    else:\n",
    "        children = []\n",
    "        parent_community = connected_components(build_wgraph(tv[row_level]))[1]\n",
    "        child_community = connected_components(build_wgraph(tv[row_level+1]))[1]\n",
    "        unique_communities = list(set(parent_community)) \n",
    "        for unique_community in unique_communities:\n",
    "            if valid_community == unique_community:\n",
    "                indices = [i for i, x in enumerate(parent_community) if x == unique_community] #[8,9]\n",
    "                seen_communities = []\n",
    "                for i in indices: #8 and 9\n",
    "                    if child_community[i] in seen_communities:\n",
    "                        filter(lambda x: x['community'] == str(child_community[i]), children)[0]['indices'].append(i)\n",
    "                    else:\n",
    "                        community_to_find = child_community[i]\n",
    "                        grow_my_children = populateTree(row_level+1, community_to_find)\n",
    "                        if grow_my_children:\n",
    "                            name = \"\"\n",
    "                            children.append({\"community\":str(child_community[i]),\"indices\":[i],\"name\" : name , \"children\":grow_my_children, \"hasChildren\": True})\n",
    "                        else:\n",
    "                            name = \" \".join([tfidf_feature_names[j] for j in nmf.components_[i].argsort()[:-n_top_words - 1:-1]])\n",
    "                            children.append({\"community\":str(child_community[i]),\"indices\":[i],\"size\":weights[i],\"name\":name, \"hasChildren\": False})\n",
    "                        seen_communities.append(child_community[i])\n",
    "        if len(children) == 1:\n",
    "            try: \n",
    "                return children[0]['children']\n",
    "            except:\n",
    "                return []\n",
    "        else:\n",
    "            return children\n",
    "        \n",
    "def recursiveNaming(tree):\n",
    "        i = tree['indices']\n",
    "        base = nmf.components_[i[0]]\n",
    "        if len(i) > 1:\n",
    "            for ind in i[1:]:\n",
    "                base = np.add(nmf.components_[ind], base)\n",
    "        tree['name'] = \" \".join([tfidf_feature_names[j] for j in base.argsort()[:-n_top_words - 1:-1]])\n",
    "        if tree['hasChildren']:\n",
    "            for child in tree['children']:\n",
    "                    recursiveNaming(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tv = greedy_TV_build(thresh_vals(100),2)\n",
    "# visualize topic tree\n",
    "# for i in tv:\n",
    "#     ccB = connected_components(build_wgraph(i))[1]\n",
    "#     print ccB\n",
    "size = len(tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flare = {\"name\" : \"\" , \"children\" : populateTree(0, 0)}\n",
    "for child in flare['children']:\n",
    "    recursiveNaming(child)\n",
    "with open('demo.json', 'w') as outfile:\n",
    "    json.dump(flare, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.063645809712599435,\n",
       " 0.07042121552949536,\n",
       " 0.071913670128555859,\n",
       " 0.076448673468941172,\n",
       " 0.12154825405128192,\n",
       " 0.15240319895942628,\n",
       " 0.17893480722565985,\n",
       " 0.41158435892964457,\n",
       " 0.43746089630853452,\n",
       " 1.0000000000000011]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
