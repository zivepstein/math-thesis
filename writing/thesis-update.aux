\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{*}
\citation{lee1999learning}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Theories for Human Image Understanding}{5}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{cup}{{2}{5}{Theories for Human Image Understanding}{chapter.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces How does your brain take the raw retinal activations of this picture and produce a mental representation of a cup?}}{5}{figure.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Part-based recognition and visual perception}{5}{section.2.1}}
\citation{palmer1977hierarchical}
\citation{biederman1987recognition}
\citation{biederman1987recognition}
\citation{biederman1987recognition}
\citation{biederman1987recognition}
\newlabel{eq:1}{{2.1}{6}{Part-based recognition and visual perception}{equation.2.1}{}}
\citation{minsky1975framework}
\citation{minsky1975framework}
\citation{minsky1975framework}
\newlabel{fig: rbc}{{2.1}{7}{Part-based recognition and visual perception}{Item.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Processing stages for object recognition proposed by the RBC Theory. Adapted from \cite  {biederman1987recognition}}}{7}{figure.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Knowledge representation as information retrieval}{7}{section.2.2}}
\citation{biederman1987recognition}
\citation{minsky1975framework}
\citation{palmer1977hierarchical}
\citation{palmer1977hierarchical}
\citation{palmer1977hierarchical}
\citation{palmer1977hierarchical}
\citation{minsky1975framework}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}The hierarchical structure of perception}{8}{section.2.3}}
\newlabel{fig:palmer}{{2.3}{8}{The hierarchical structure of perception}{section.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces The hierarchical relationship network used to represent perceptual information. At each level of the hierarchy, a structural unit (SU) is a combination of values (V) on global properties (P) and structural relationships to other structural units. Adapted from \cite  {palmer1977hierarchical}}}{8}{figure.2.3}}
\citation{biederman1987recognition}
\citation{biederman1987recognition}
\citation{biederman1987recognition}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Interpretations for Algorithmic Formulation}{9}{section.2.4}}
\newlabel{interp}{{2.4}{9}{Interpretations for Algorithmic Formulation}{section.2.4}{}}
\newlabel{manifold}{{2.4}{9}{Object Classification as Supervised Manifold Learning}{section*.2}{}}
\newlabel{fig:geonLC}{{2.4}{9}{Geons as Topics}{section*.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces An image can be represented as a linear combination of geons. Elephant adapted from \cite  {biederman1987recognition}.}}{9}{figure.2.4}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ why is this true??}{10}{section*.4}}
\pgfsyspdfmark {pgfid1}{12586416}{42079027}
\pgfsyspdfmark {pgfid4}{37602919}{42093772}
\pgfsyspdfmark {pgfid5}{39028327}{41825075}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Algorithms for Representing Data}{11}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chapter:techniques}{{3}{11}{Algorithms for Representing Data}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Singular Value Decomposition}{11}{section.3.1}}
\newlabel{section:svd}{{3.1}{11}{Singular Value Decomposition}{section.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Neural Network Representation}{13}{section.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Left: a very simple neural network with 3-dimensional input (red), one hidden layer with 4 hidden units (blue), and 2-dimensional output (green). Right: A pictorial representation of a convolutional layer of a neural network.}}{13}{figure.3.1}}
\citation{hornik1991approximation}
\citation{rumelhart1988learning}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Matrix factorization}{14}{section.3.3}}
\citation{lee1999learning}
\citation{paatero1994positive}
\citation{lee1999learning}
\newlabel{nnmf}{{3.3}{15}{Matrix factorization}{section.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces A visual representation of the non-negative matrix factorization}}{15}{figure.3.2}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Multiplicative Update}}{16}{algocf.1}}
\citation{lee1999learning}
\citation{lee1999learning}
\citation{lee1999learning}
\citation{turk1991eigenfaces}
\citation{amodei2015deep}
\citation{hannun2014deep}
\citation{hannun2014deep}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Types of Data}{17}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Image}{17}{section.4.1}}
\newlabel{image}{{4.1}{17}{Image}{section.4.1}{}}
\citation{kawamoto2000estimation}
\citation{krause2015non}
\citation{holzapfel2008musical}
\citation{holzapfel2008musical}
\citation{ho2008nonnegative}
\newlabel{fig:face}{{4.1}{18}{Image}{section.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces A comparison of the basis vectors learned for NMF, VQ and PCA. Adapted from \cite  {lee1999learning}}}{18}{figure.4.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Sound}{18}{section.4.2}}
\citation{vavasis2009complexity}
\newlabel{fig:sound}{{4.2}{19}{Sound}{section.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Pairwise comparison of music genres. Adapted from \cite  {holzapfel2008musical}}}{19}{figure.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Graph}{19}{section.4.3}}
\citation{lee1999learning}
\citation{blei2012probabilistic}
\citation{blei2012probabilistic}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Natural Language}{20}{section.4.4}}
\newlabel{natlang}{{4.4}{20}{Natural Language}{section.4.4}{}}
\newlabel{fig:tmex}{{4.4}{21}{Natural Language}{section.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces A visual interpretation of topic model on text. Adapted from \cite  {blei2012probabilistic}}}{21}{figure.4.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Traditional NNMF and SVD on Test and Field Data}{22}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{basic}{{5}{22}{Traditional NNMF and SVD on Test and Field Data}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Comparison of NNMF and SVD}{22}{section.5.1}}
\citation{20news}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Datasets}{23}{section.5.2}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ what is his name?}{23}{section*.8}}
\pgfsyspdfmark {pgfid11}{4736286}{22644324}
\pgfsyspdfmark {pgfid14}{37602919}{22659069}
\pgfsyspdfmark {pgfid15}{39028327}{22390372}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ run these}{23}{section*.10}}
\pgfsyspdfmark {pgfid16}{4736286}{18288363}
\pgfsyspdfmark {pgfid19}{37602919}{18303108}
\pgfsyspdfmark {pgfid20}{39028327}{18034411}
\citation{cai2008non}
\citation{dicarlo2012does}
\citation{belkin2001laplacian}
\citation{cai2008non}
\citation{cai2008non}
\citation{belkin2003problems}
\citation{chung1997spectral}
\citation{chung1997spectral}
\citation{belkin2003problems}
\citation{cai2008non}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Manifold Learning as NNMF}{24}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{supervised}{{6}{24}{Manifold Learning as NNMF}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Motivation}{24}{section.6.1}}
\newlabel{O:gNNMF}{{6.1}{25}{Manifold Smoothness}{equation.6.1}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Multiplicative Update for Graph Regularized NNMF}}{25}{algocf.2}}
\citation{biederman1987recognition}
\citation{dicarlo2012does}
\citation{dicarlo2012does}
\citation{gross1994inferior}
\citation{dicarlo2012does}
\citation{miyashita1993inferior}
\citation{orban2008higher}
\citation{rolls2000functions}
\citation{lee2010semi}
\citation{lee2010semi}
\newlabel{manifold}{{6.1}{26}{Supervision}{section*.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces A: Supervised representation of object recognition; B: seperating hyperplane via ventral stream transform. Image adapted from \cite  {dicarlo2012does}.}}{26}{figure.6.1}}
\newlabel{O:ssMMMF}{{6.3}{26}{Supervision}{equation.6.3}{}}
\newlabel{fig:semi}{{6.1}{27}{Supervision}{algocf.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces ssNNMF by label}}{27}{figure.6.2}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Multiplicative Update for Semi-Supervised NNMF}}{27}{algocf.3}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Manifold NNMF}{27}{section.6.2}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ what else is there to do here?}{27}{section*.13}}
\pgfsyspdfmark {pgfid21}{4736286}{6494772}
\pgfsyspdfmark {pgfid24}{37602919}{6509517}
\pgfsyspdfmark {pgfid25}{39028327}{6240820}
\citation{nnmfimp}
\citation{nnmfimp}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Hierarchical Representation}{28}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Approach}{28}{section.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces How the tree structure is formed for the connected componenet vectors}}{29}{figure.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Left: Visualization of hierarchical topics in standard NMF; Right: Visualization of hierarchical topics in SSNMF; }}{30}{figure.7.2}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Visualization}{30}{section.7.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces Topics used in hierarchical topic model}}{31}{figure.7.3}}
\citation{trigeorgis2014deep}
\citation{trigeorgis2014deep}
\citation{deepNonNeg}
\citation{trigeorgis2014deep}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Deep Models}{32}{chapter.8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Approach}{32}{section.8.1}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Deep Neural Models}{32}{section.8.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Discussion}{33}{chapter.9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\bibstyle{plain}
\bibdata{myBib}
\bibcite{amodei2015deep}{1}
\bibcite{belkin2003problems}{2}
\bibcite{belkin2001laplacian}{3}
\bibcite{biederman1987recognition}{4}
\bibcite{blei2012probabilistic}{5}
\bibcite{cai2008non}{6}
\bibcite{chung1997spectral}{7}
\bibcite{dicarlo2012does}{8}
\bibcite{deepNonNeg}{9}
\bibcite{fortunato2010community}{10}
\bibcite{griffiths2004hierarchical}{11}
\bibcite{gross1994inferior}{12}
\bibcite{hannun2014deep}{13}
\bibcite{ho2008nonnegative}{14}
\bibcite{holzapfel2008musical}{15}
\bibcite{hornik1991approximation}{16}
\bibcite{kawamoto2000estimation}{17}
\bibcite{krause2015non}{18}
\bibcite{lancichinetti2009detecting}{19}
\bibcite{lee1997unsupervised}{20}
\bibcite{lee1999learning}{21}
\bibcite{lee2010semi}{22}
\bibcite{logothetis1996visual}{23}
\bibcite{minsky1975framework}{24}
\bibcite{miyashita1993inferior}{25}
\bibcite{orban2008higher}{26}
\bibcite{paatero1994positive}{27}
\bibcite{palmer1977hierarchical}{28}
\bibcite{20news}{29}
\bibcite{rolls2000functions}{30}
\bibcite{rumelhart1988learning}{31}
\bibcite{nnmfimp}{32}
\bibcite{trigeorgis2014deep}{33}
\bibcite{turk1991eigenfaces}{34}
\bibcite{ullman1996high}{35}
\bibcite{vavasis2009complexity}{36}
\bibcite{wachsmuth1994recognition}{37}
