\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{*}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Theories for Human Image Understanding}{4}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{cup}{{2}{4}{Theories for Human Image Understanding}{chapter.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces How does your brain take the raw retinal activations of this picture and produce a mental representation of a cup?}}{4}{figure.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Part-based recognition and visual perception}{4}{section.2.1}}
\citation{palmer1977hierarchical}
\citation{biederman1987recognition}
\citation{biederman1987recognition}
\citation{biederman1987recognition}
\citation{biederman1987recognition}
\newlabel{eq:1}{{2.1}{5}{Part-based recognition and visual perception}{equation.2.1}{}}
\citation{minsky1975framework}
\citation{minsky1975framework}
\citation{minsky1975framework}
\newlabel{fig: rbc}{{2.1}{6}{Part-based recognition and visual perception}{Item.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Processing stages for object recognition proposed by the RBC Theory. Adapted from \cite  {biederman1987recognition}}}{6}{figure.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Knowledge representation as information retrieval}{6}{section.2.2}}
\citation{biederman1987recognition}
\citation{minsky1975framework}
\citation{palmer1977hierarchical}
\citation{palmer1977hierarchical}
\citation{palmer1977hierarchical}
\citation{palmer1977hierarchical}
\citation{minsky1975framework}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}The hierarchical structure of perception}{7}{section.2.3}}
\newlabel{fig:palmer}{{2.3}{7}{The hierarchical structure of perception}{section.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces The hierarchical relationship network used to represent perceptual information. At each level of the hierarchy, a structural unit (SU) is a combination of values (V) on global properties (P) and structural relationships to other structural units. Adapted from \cite  {palmer1977hierarchical}}}{7}{figure.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Interpretations for Algorithmic Formulation}{8}{section.2.4}}
\newlabel{interp}{{2.4}{8}{Interpretations for Algorithmic Formulation}{section.2.4}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ finish these and make figures}{8}{section*.1}}
\pgfsyspdfmark {pgfid1}{19860434}{30120890}
\pgfsyspdfmark {pgfid4}{37602919}{30135635}
\pgfsyspdfmark {pgfid5}{39028327}{29866938}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Techniques}{9}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chapter:techniques}{{3}{9}{Techniques}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Singular Value Decomposition}{9}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Neural Network Representation}{11}{section.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Left: a very simple neural network with 3-dimensional input (red), one hidden layer with 4 hidden units (blue), and 2-dimensional output (green). Right: A pictorial representation of a convolutional layer of a neural network.}}{11}{figure.3.1}}
\citation{hornik1991approximation}
\citation{rumelhart1988learning}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Matrix factorization}{12}{section.3.3}}
\citation{lee1999learning}
\citation{paatero1994positive}
\citation{lee1999learning}
\newlabel{nnmf}{{3.3}{13}{Matrix factorization}{section.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces A visual representation of the non-negative matrix factorization}}{13}{figure.3.2}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Multiplicative Update}}{14}{algocf.1}}
\citation{lee1999learning}
\citation{lee1999learning}
\citation{lee1999learning}
\citation{turk1991eigenfaces}
\citation{amodei2015deep}
\citation{hannun2014deep}
\citation{hannun2014deep}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Types of Data}{15}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Image}{15}{section.4.1}}
\newlabel{image}{{4.1}{15}{Image}{section.4.1}{}}
\citation{kawamoto2000estimation}
\citation{krause2015non}
\citation{ho2008nonnegative}
\newlabel{fig:face}{{4.1}{16}{Image}{section.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces A comparison of the basis vectors learned for NMF, VQ and PCA. Adapted from \cite  {lee1999learning}}}{16}{figure.4.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Sound}{16}{section.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Graph}{16}{section.4.3}}
\citation{vavasis2009complexity}
\citation{lee1999learning}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Natural Language}{17}{section.4.4}}
\citation{lee2010semi}
\citation{lee2010semi}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Semi-Supervised NNMF}{19}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Approach}{19}{section.5.1}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Multiplicative Update for Semi-Supervised NNMF}}{20}{algocf.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Visualization}{20}{section.5.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Hierarchical Representation}{21}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Approach}{21}{section.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces How the tree structure is formed for the connected componenet vectors}}{22}{figure.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Left: Visualization of hierarchical topics in standard NMF; Right: Visualization of hierarchical topics in SSNMF; }}{23}{figure.6.2}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Visualization}{23}{section.6.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Topics used in hierarchical topic model}}{24}{figure.6.3}}
\citation{trigeorgis2014deep}
\citation{trigeorgis2014deep}
\citation{deepNonNeg}
\citation{trigeorgis2014deep}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Deep Models}{25}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Approach}{25}{section.7.1}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Deep Neural Models}{25}{section.7.2}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Visualization}{25}{section.7.3}}
\bibstyle{plain}
\bibdata{myBib}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Discussion}{26}{chapter.8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\bibcite{amodei2015deep}{1}
\bibcite{biederman1987recognition}{2}
\bibcite{deepNonNeg}{3}
\bibcite{fortunato2010community}{4}
\bibcite{griffiths2004hierarchical}{5}
\bibcite{hannun2014deep}{6}
\bibcite{ho2008nonnegative}{7}
\bibcite{hornik1991approximation}{8}
\bibcite{kawamoto2000estimation}{9}
\bibcite{krause2015non}{10}
\bibcite{lancichinetti2009detecting}{11}
\bibcite{lee1997unsupervised}{12}
\bibcite{lee1999learning}{13}
\bibcite{lee2010semi}{14}
\bibcite{logothetis1996visual}{15}
\bibcite{minsky1975framework}{16}
\bibcite{paatero1994positive}{17}
\bibcite{palmer1977hierarchical}{18}
\bibcite{rumelhart1988learning}{19}
\bibcite{trigeorgis2014deep}{20}
\bibcite{turk1991eigenfaces}{21}
\bibcite{ullman1996high}{22}
\bibcite{vavasis2009complexity}{23}
\bibcite{wachsmuth1994recognition}{24}
